# rag_core.py (AI ë‘ë‡Œ ì „ìš© íŒŒì¼)
import os
import re
import pickle
import google.generativeai as genai

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever

# 1. ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ì ìš©!)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_FAISS_PATH = os.path.join(BASE_DIR, "faiss_index")
DB_BM25_PATH = os.path.join(BASE_DIR, "bm25_retriever.pkl")
EMBEDDING_MODEL = "BAAI/bge-m3"

# 2. API í‚¤ ì„¤ì •
if "GOOGLE_API_KEY" in os.environ:
    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
else:
    pass

# 3. DB ë¡œë”
def load_resources():
    print("Loading Vector DB & BM25...")
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )
    
    vector_db = None
    bm25_retriever = None

    if os.path.exists(DB_FAISS_PATH):
        vector_db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)
    
    if os.path.exists(DB_BM25_PATH):
        with open(DB_BM25_PATH, "rb") as f:
            bm25_retriever = pickle.load(f)
            bm25_retriever.k = 10
            
    return vector_db, bm25_retriever

vector_db, bm25_retriever = load_resources()

if vector_db:
    faiss_retriever = vector_db.as_retriever(search_kwargs={"k": 10})
else:
    faiss_retriever = None


# 4. ì•™ìƒë¸” ê²€ìƒ‰ê¸°
class EnsembleRetriever:
    def __init__(self, retrievers, weights=None, k=3):
        self.retrievers = retrievers
        self.weights = weights or [1.0] * len(retrievers)
        self.k = k

    def invoke(self, query):
        scored = {}
        seen_docs = {}

        for retriever, weight in zip(self.retrievers, self.weights):
            if retriever is None:
                continue
            try:
                if hasattr(retriever, "invoke"):
                    docs = retriever.invoke(query)
                else:
                    docs = retriever.get_relevant_documents(query)
            except:
                docs = []

            docs = docs[:10]
            for rank, doc in enumerate(docs):
                key = (doc.page_content, tuple(sorted(doc.metadata.items())))
                score = weight * (10 - rank)
                if key not in scored:
                    scored[key] = score
                    seen_docs[key] = doc
                else:
                    scored[key] += score
        
        sorted_keys = sorted(scored.keys(), key=lambda k: -scored[k])
        return [seen_docs[key] for key in sorted_keys[: self.k]]

# ì´ˆê¸°í™”
ensemble = None
if vector_db and bm25_retriever:
    ensemble = EnsembleRetriever(
        retrievers=[bm25_retriever, faiss_retriever],
        weights=[0.3, 0.7],
        k=5,
    )


# 5. í•µì‹¬ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def get_ai_response(user_input):
    if not ensemble:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # (1) ê²€ìƒ‰
    docs = ensemble.invoke(user_input)

    final_seen = set()
    unique_docs = []
    for d in docs:
        key = f"{d.metadata.get('source','')}_{d.metadata.get('title','')}"
        if key not in final_seen:
            final_seen.add(key)
            unique_docs.append(d)

    # (2) í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context = ""
    for i, d in enumerate(unique_docs):
        context += f"--- ë¬¸ì„œ {i+1} ---\n"
        context += f"ì œëª©: {d.metadata.get('title')}\n"
        context += f"ì¶œì²˜: {d.metadata.get('source')}\n"
        context += d.metadata.get("raw_content", d.page_content) + "\n\n"

    system_message = """
    í•­ê³µëŒ€ì™€ ê´€ë ¨ëœ ê³µì‹ ë¬¸ì„œ, ê³µì§€ì‚¬í•­, í•™ì‚¬ ì¼ì •, ê·œì • ë“±ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    [ë‹µë³€ ì›ì¹™]
    1. ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œì™€ ë°ì´í„°ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤.
    2. ë¬¸ì„œì— ì—†ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ì„ì˜ë¡œ ì§€ì–´ë‚´ì§€ ë§ê³ , "í•´ë‹¹ ë‚´ìš©ì€ ë¬¸ì„œì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."ë¼ê³  ë§í•˜ì„¸ìš”.
    3. í•™ìƒë“¤ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì§§ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
    5. ë‹µë³€ ë§ˆì§€ë§‰ì— ì°¸ê³ í•œ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ [ê·¼ê±°: 1, 3] í˜•íƒœë¡œ ë¶™ì´ì„¸ìš”.
    6. ë¬¸ì„œ ê°„ ë‚´ìš© ì¶©ëŒì´ ìˆì„ ê²½ìš°, ìµœì‹  ë¬¸ì„œ(ë²ˆí˜¸ê°€ ê°€ì¥ í° ê²ƒ)ë¥¼ ìš°ì„ í•©ë‹ˆë‹¤.

    [ì¶”ê°€ ê·œì¹™]
    - í•™ì‚¬ì¼ì •, ìˆ˜ì—…, ì‹œí—˜, ì¥í•™ê¸ˆ, ë“±ë¡ê¸ˆ ë“± í•™ìƒ ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•©ë‹ˆë‹¤.
    - ê°œì¸ ì •ë³´, ë¯¼ê°í•œ ì¡°ì–¸(ë²•ë¥ , ì˜í•™ ë“±), ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš©ì€ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ë©´ ëª…í™•í•œ ë‹µë³€ì„ ìœ„í•´ ì¶”ê°€ ì§ˆë¬¸ì„ ìš”ì²­í•˜ì„¸ìš”.
    - ë‹µë³€ì—ëŠ” ì–´ë–¤ í˜•íƒœì˜ URL, ë§í¬, ì¶œì²˜ ë§í¬ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    """

    final_prompt = f"{system_message}\n\n[Context]\n{context}\n\n[ì§ˆë¬¸]\n{user_input}\n\n[ë‹µë³€]"

    # (3) Gemini í˜¸ì¶œ
    try:
        model = genai.GenerativeModel("gemini-2.5-pro")
        response = model.generate_content(final_prompt)
        full_text = response.text
    except Exception as e:
        return f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    # (4) ì¶œì²˜ íƒœê·¸ ì œê±°
    source_matches = re.findall(r"\[ê·¼ê±°:\s*([\d,\s]+)\]", full_text)
    final_content = re.sub(r"\[ê·¼ê±°:[^\]]*\]", "", full_text).strip()

    footer_items = []
    used_indexes = set()

    if source_matches:
        for match in source_matches:
            indexes = match.replace(" ", "").split(",")
            for idx in indexes:
                if idx.isdigit():
                    num = int(idx)
                    if num not in used_indexes:
                        used_indexes.add(num)
                        doc_index = num - 1
                        if 0 <= doc_index < len(unique_docs):
                            doc = unique_docs[doc_index]

                            title = doc.metadata.get("title", "ì œëª© ì—†ìŒ")
                            url = doc.metadata.get("source", "")
                            if url:
                                footer_items.append(f"- [{title}]({url})")

                            # â˜… ì²¨ë¶€íŒŒì¼ ì¶”ê°€
                            attach_raw = doc.metadata.get("attachments")
                            if attach_raw:
                                for item in attach_raw.split(";"):
                                    parts = item.split("|")
                                    if len(parts) == 2:
                                        fname, furl = parts
                                        footer_items.append(f"- ğŸ“ [{fname}]({furl})")

    if footer_items:
        final_content += "\n\n---\n**ì°¸ê³ í•œ ì¶œì²˜:**\n" + "\n".join(footer_items)

    return final_content
