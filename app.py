import os
import re
import pickle

import streamlit as st
import google.generativeai as genai

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document

# -------------------------
# 1. ì´ˆê¸° ì„¤ì •
# -------------------------
st.set_page_config(page_title="í•œêµ­í•­ê³µëŒ€í•™êµ RAG ì±—ë´‡", page_icon="âœˆï¸")
st.title("âœˆï¸ í•œêµ­í•­ê³µëŒ€í•™êµ RAG ì±—ë´‡")
st.caption("ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì‹œë©´ êµë‚´ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")

DB_FAISS_PATH = r"C:\Users\sswon\source\repos\PythonApplication1\PythonApplication1\faiss_index"
DB_BM25_PATH = r"C:\Users\sswon\source\repos\PythonApplication1\PythonApplication1\bm25_retriever.pkl"

EMBEDDING_MODEL = "BAAI/bge-m3"


# -------------------------
# 2. Vector DB + BM25 ë¡œë”©
# -------------------------
@st.cache_resource
def load_vector_db():
    if not os.path.exists(DB_FAISS_PATH):
        return None
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL,
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
        )
        db = FAISS.load_local(
            DB_FAISS_PATH,
            embeddings,
            allow_dangerous_deserialization=True,
        )
        return db
    except Exception as e:
        st.error(f"Vector DB ë¡œë”© ì˜¤ë¥˜: {e}")
        return None


@st.cache_resource
def load_bm25_retriever():
    if not os.path.exists(DB_BM25_PATH):
        return None
    try:
        with open(DB_BM25_PATH, "rb") as f:
            return pickle.load(f)
    except Exception as e:
        st.error(f"BM25 ë¡œë”© ì˜¤ë¥˜: {e}")
        return None


vector_db = load_vector_db()
bm25_retriever: BM25Retriever = load_bm25_retriever()

if vector_db is None or bm25_retriever is None:
    st.error("FAISS ë˜ëŠ” BM25 ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
    st.stop()

faiss_retriever = vector_db.as_retriever(search_kwargs={"k": 10})
bm25_retriever.k = 10


# -------------------------
# 4. Ensemble Retriever (ìµœì í™” ë²„ì „)
# -------------------------
class EnsembleRetriever:
    def __init__(self, retrievers, weights=None, k=3):
        self.retrievers = retrievers
        self.weights = weights or [1.0] * len(retrievers)
        self.k = k

    def _fetch_docs(self, retriever, query):
        if hasattr(retriever, "invoke"):
            try:
                return retriever.invoke(query) or []
            except Exception:
                pass

        if hasattr(retriever, "get_relevant_documents"):
            try:
                return retriever.get_relevant_documents(query) or []
            except Exception:
                pass

        return []

    def invoke(self, query):
        scored = {}
        seen_docs = {}

        for retriever, weight in zip(self.retrievers, self.weights):
            docs = self._fetch_docs(retriever, query)

            # ğŸ”¥ retrieverë³„ ìµœëŒ€ 10ê°œë§Œ ì‚¬ìš©
            docs = docs[:10]

            for rank, doc in enumerate(docs):
                key = (doc.page_content, tuple(sorted(doc.metadata.items())))
                score = weight * (10 - rank)


                if key not in scored:
                    scored[key] = score
                    seen_docs[key] = doc
                else:
                    scored[key] += score

        # ğŸ”¥ ì ìˆ˜ìˆœ ì •ë ¬
        sorted_keys = sorted(scored.keys(), key=lambda k: -scored[k])

        result_docs = []
        for key in sorted_keys[: self.k]:
            result_docs.append(seen_docs[key])

        return result_docs


ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, faiss_retriever],
    weights=[0.3, 0.7],   # ìˆ˜ì •ëœ ê°€ì¤‘ì¹˜
    k=5,
)


# -------------------------
# 5. get_relevant_documents (ê°„ê²° ìµœì í™”)
# -------------------------
def get_relevant_documents(query: str):
    return ensemble_retriever.invoke(query)


# -------------------------
# 6. Gemini LLM
# -------------------------
if "GOOGLE_API_KEY" not in st.secrets:
    st.error("GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsì— ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

system_message = """
ë‹¹ì‹ ì€ í•œêµ­í•­ê³µëŒ€í•™êµ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
ë¬¸ì„œì˜ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì‹ ë¢°ë„ ë†’ì€ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

[ë§¤ìš° ì¤‘ìš”] ì¶œì²˜ í‘œê¸° ê·œì¹™:
1. ë‹µë³€ ìƒì„± í›„, ë°˜ë“œì‹œ ìì‹ ì´ ì£¼ìš” ê·¼ê±°ë¡œ ì‚¬ìš©í•œ 'ë¬¸ì„œ N'ì˜ ë²ˆí˜¸ë¥¼ [ê·¼ê±°: N] í˜•íƒœë¡œ ë¶™ì´ì„¸ìš”.
"""


def get_gemini_response_stream(prompt: str):
    try:
        model = genai.GenerativeModel("gemini-2.5-pro")
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            try:
                yield chunk.text
            except Exception:
                continue
    except Exception as e:
        st.error(f"Gemini ì˜¤ë¥˜: {e}")
        yield ""


# -------------------------
# 7. ì´ì „ ì§ˆë¬¸ ê¸°ì–µ ì‚­ì œë¨
# -------------------------


# -------------------------
# 8. Streamlit UI
# -------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):

    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        full = ""

        with st.spinner("ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”... ğŸ¤”"):

            combined_query = user_input.strip()
            # í„°ë¯¸ë„ì— ì¶œë ¥í•˜ëŠ” ë¶€ë¶„ (í•„ìš”í•˜ë©´ ì£¼ì„ ì§€ìš°ê³  ì‚¬ìš©)
            print("=" * 50)
            print(f"Query: {combined_query}")
            #
            # ------------------------------
            # BM25 ê²€ìƒ‰ (ì¤‘ë³µ ì œê±° í¬í•¨ 15ê°œ)
            # ------------------------------
            bm25_only = bm25_retriever.invoke(combined_query)
            bm25_seen = set()
            bm25_unique = []

            for d in bm25_only:
                key = f"{d.metadata.get('source','')}_{d.metadata.get('title','')}"
                if key not in bm25_seen:
                    bm25_seen.add(key)
                    bm25_unique.append(d)
                if len(bm25_unique) >= 10:
                    break
            #ê²€ìƒ‰ ê²°ê³¼ í„°ë¯¸ë„ì— ì¶œë ¥í•˜ëŠ” ë¶€ë¶„
            print("\n--- ğŸŸ¡ BM25 ê²€ìƒ‰ ê²°ê³¼ ---")
            for i, d in enumerate(bm25_unique, 1):
                print(f"[BM25 {i}] {d.metadata.get('title')}")
            #
            # ------------------------------
            # FAISS ê²€ìƒ‰ (ì¤‘ë³µ ì œê±° í¬í•¨ 15ê°œ)
            # ------------------------------
            faiss_only = faiss_retriever.invoke(combined_query)
            faiss_seen = set()
            faiss_unique = []

            for d in faiss_only:
                key = f"{d.metadata.get('source','')}_{d.metadata.get('title','')}"
                if key not in faiss_seen:
                    faiss_seen.add(key)
                    faiss_unique.append(d)
                if len(faiss_unique) >= 10:
                    break
            #ê²€ìƒ‰ ê²°ê³¼ í„°ë¯¸ë„ì— ì¶œë ¥
            print("\n--- ğŸ”µ FAISS ê²€ìƒ‰ ê²°ê³¼ ---")
            for i, d in enumerate(faiss_unique, 1):
                print(f"[FAISS {i}] {d.metadata.get('title')}")
            #
            # ------------------------------
            # ì•™ìƒë¸” ìµœì¢…
            # ------------------------------
            docs = get_relevant_documents(combined_query)

            # ğŸ”¥ ìµœì¢… ì¤‘ë³µ ì œê±°
            final_seen = set()
            unique_final_docs = []

            for d in docs:
                key = f"{d.metadata.get('source','')}_{d.metadata.get('title','')}"
                if key not in final_seen:
                    final_seen.add(key)
                    unique_final_docs.append(d)
            #í„°ë¯¸ë„ì— ì¶œë ¥
            print("\n--- ğŸ”´ ì•™ìƒë¸” ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ---")
            for i, d in enumerate(unique_final_docs, 1):
                print(f"[FINAL {i}] [{d.metadata.get('title')}] ({d.metadata.get('source')})")

            print("====================================================")
            #
            # ì´í›„ LLM ë¬¸ë§¥ ìƒì„± ì‹œì—ë„ unique_final_docs ì‚¬ìš©
            context = ""
            for i, d in enumerate(unique_final_docs):
                context += f"--- ë¬¸ì„œ {i+1} ---\n"
                context += f"ì œëª©: {d.metadata.get('title')}\n"
                context += f"ì¶œì²˜: {d.metadata.get('source')}\n"
                context += d.metadata.get("raw_content", d.page_content) + "\n\n"

            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±ë„ ì´ê±¸ë¡œ ìœ ì§€ë¨

            final_prompt = (
                system_message
                + "\n\n[Context]\n"
                + context
                + f"\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_input}"
                + "\n\n[ë‹µë³€] (ì¶œì²˜ í‘œê¸° ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”.)"
            )

            placeholder = st.empty()

            for t in get_gemini_response_stream(final_prompt):
                full += t
                placeholder.markdown(full + "â–Œ")

        # -------------------------
        # ê·¼ê±° íƒœê·¸ íŒŒì‹±
        # -------------------------
        source_matches = re.findall(r"\[ê·¼ê±°:\s*([\d,\s]+)\]", full)
        final_content = re.sub(r"\[ê·¼ê±°:[^\]]*\]", "", full).strip()

        footer_items = []
        used_indexes = set()

        if source_matches:
            try:
                for match in source_matches:
                    indexes = match.replace(" ", "").split(",")

                    for idx in indexes:
                        if not idx.isdigit():
                            continue

                        num = int(idx)
                        if num in used_indexes:
                            continue
                        used_indexes.add(num)

                        doc_index = num - 1

                        if 0 <= doc_index < len(docs):
                            doc_to_cite = docs[doc_index]
                            source_url = doc_to_cite.metadata.get("source")
                            source_title = doc_to_cite.metadata.get("title", "ì œëª© ì—†ìŒ")
                            attachment_str = doc_to_cite.metadata.get("attachments")

                            if source_url:
                                footer_items.append(f"- [{source_title}]({source_url})")

                            if attachment_str:
                                first_item = attachment_str.split(";")[0]
                                parts = first_item.split("|")
                                if len(parts) == 2:
                                    filename, file_url = parts
                                    footer_items.append(
                                        f"- ğŸ“ [{filename} (ì²¨ë¶€íŒŒì¼)]({file_url})"
                                    )

            except Exception as e:
                print(f"ê·¼ê±° íƒœê·¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        footer_items = list(dict.fromkeys(footer_items))

        if footer_items:
            final_content += "\n\n---\n**ì°¸ê³ í•œ ì¶œì²˜:**\n" + "\n".join(footer_items)

        placeholder.markdown(final_content)
        st.session_state.messages.append({"role": "assistant", "content": final_content})


